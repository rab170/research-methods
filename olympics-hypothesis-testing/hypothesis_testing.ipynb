{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Research Methods \n",
    "## 2012 Olympics Hypothesis Testing\n",
    "\n",
    "**04. December 2017**\n",
    "\n",
    "Fabian Karl & Robert Brown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import scipy.optimize as opt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('london-2012.csv', thousands=',')\n",
    "df = df.drop(['Unnamed: 44'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, lets create a few simple plots and investigate linear correlations between a few variables using the fisher transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fisher_transform = lambda r_xy: 0.5*np.log((1+r_xy)/(1-r_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['NOC SIZE'], df['Total'])\n",
    "plt.show()\n",
    "\n",
    "r = np.corrcoef(df['NOC SIZE'], df['Total'])[0][1]\n",
    "z = fisher_transform(r)\n",
    "print 'p value: {0}'.format(2*stats.norm.sf(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['GDP.2011'], df['Total'])\n",
    "plt.show()\n",
    "\n",
    "r = np.corrcoef(df['GDP.2011'], df['Total'])[0][1]\n",
    "z = fisher_transform(r)\n",
    "print 'p value: {0}'.format(2*stats.norm.sf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "GDP seems to have a similarly important linear relationship with metals won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['pop.2010'], df['Total'])\n",
    "plt.show()\n",
    "\n",
    "r = np.corrcoef(df['pop.2010'], df['Total'])[0][1]\n",
    "z = fisher_transform(r)\n",
    "print 'p value: {0}'.format(2*stats.norm.sf(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = df.median().keys()\n",
    "def centeral_limit_theorem_samples(split_with, N = 30, M = 1000):\n",
    "    median = df[split_with].median()\n",
    "    below = df[df[split_with] <= median]\n",
    "    above = df[df[split_with] > median]\n",
    "\n",
    "    samples = {'above':[], 'below':[]}\n",
    "    for _ in range(M):\n",
    "        samples['above'].append(above.sample(N).mean())\n",
    "        samples['below'].append(below.sample(N).mean())\n",
    "        \n",
    "    mu = {'above':{}, 'below':{}}\n",
    "    for row in rows:\n",
    "        mu['above'][row] = list(map(lambda x: x[row], samples['above']))\n",
    "        mu['below'][row] = list(map(lambda x: x[row], samples['below']))\n",
    "    return samples, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split_feature = 'GDP.2011'\n",
    "samples, mu = centeral_limit_theorem_samples(split_feature, N = 25, M = 100)\n",
    "\n",
    "for feature in ['Total', 'NOC SIZE', 'Athlete rank score']:\n",
    "    a = mu['above'][feature]\n",
    "    b = mu['below'][feature]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    axes = fig.add_subplot(111)\n",
    "\n",
    "    bins=np.histogram(np.hstack((a,b)), bins=15)[1]\n",
    "    axes.hist(a, bins, label = '{0} above median'.format(split_feature))\n",
    "    axes.hist(b, bins, label = '{0} below median'.format(split_feature), alpha=0.5)\n",
    "    axes.set_title(feature)\n",
    "    axes.legend(loc=2);\n",
    "    plt.show(fig)\n",
    "\n",
    "    res = stats.ttest_ind(a, b, equal_var=False)\n",
    "    print 'p value: {0}'.format(res.pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These are all unbelievably significant (literally). Lets find a super biased feature and see if we can even reject a null-hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "split_feature = 'pop.2010'\n",
    "samples, mu = centeral_limit_theorem_samples(split_feature, N = 25, M = 100)\n",
    "\n",
    "for feature in ['Pop rank']:\n",
    "    a = mu['above'][feature]\n",
    "    b = mu['below'][feature]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    axes = fig.add_subplot(111)\n",
    "\n",
    "    bins=np.histogram(np.hstack((a,b)), bins=15)[1]\n",
    "    axes.hist(a, bins, label = '{0} above median'.format(split_feature))\n",
    "    axes.hist(b, bins, label = '{0} below median'.format(split_feature), alpha=0.5)\n",
    "    axes.set_title(feature)\n",
    "    axes.legend(loc=2);\n",
    "    plt.show(fig)\n",
    "\n",
    "    res = stats.ttest_ind(a, b, equal_var=False)\n",
    "    print res.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split_feature = 'pop.2010'\n",
    "for M in [25, 100, 500]:\n",
    "    samples, mu = centeral_limit_theorem_samples(split_feature, M = M)\n",
    "\n",
    "    b = map(lambda x: x + 3*np.std(a), a)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    axes = fig.add_subplot(111)\n",
    "\n",
    "    bins=np.histogram(np.hstack((a,b)), bins=15)[1]\n",
    "    axes.hist(a, bins)\n",
    "    axes.hist(b, bins, alpha=0.5)\n",
    "    plt.show(fig)\n",
    "\n",
    "    res = stats.ttest_ind(a, b, equal_var=False)\n",
    "    print res.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
